

<p><a href="#db">Deductive databases</a>, <a href="#csp">constraint satisfaction</a>, <a href="#lp">Prolog</a>, and <a href="#fv">formal verification</a> are often defined as special cases of first-order logic.  Here we define their simplest incarnations from the perspective of Herbrand logic, where the resulting definitions are identical to those usually given in for example Ullman's <i>Database and Knowledge-base Systems</i> or Lloyd's <i>Foundations of Logic Programming</i> book.  Because Herbrand semantics is simpler to teach and understand than first-order logic, we hope our introduction to the foundations of these three applications are more accessible than the first-order introduction to those not familiar with logic.

<a name="bilevel"><h1>Bilevel Reasoning</h1></a>
<p>All four applications of Herbrand logic can be defined in a common framework: Bilevel Reasoning (BR).  Bilevel reasoning focuses on reasoning about a pair \ltstruct\Gamma, M\gtstruct, where M is a model and \Gamma is a set of axioms.  \Gamma conservatively extends the model M.  The idea is that the model M picks out one world in the vocabulary V and the axioms \Gamma extend the theory defined by M to some theory in vocabulary V', which is larger than V.  

<p><b>Definition (Bilevel Pair)</b>: A bilevel pair is \ltstruct\Gamma, M\gtstruct, where M is a Herbrand model, \Gamma is a set of axioms, and vocabulary[\Gamma]\cupvocabulary[M] is a vocabulary, denoted vocabulary[\ltstruct\Gamma,M\gtstruct].

<p>Satisfaction for bilevel pairs can be defined using the notion of a model's reduct, which is just a way of talking about the portion of a model in a shrunken vocabulary.

<p><b>Definition (Reduct)</b>: The reduct of model M wrt vocabulary V, written Reduct[M,V] is the intersection of M and the ground atoms of V.

<p><b>Definition (Bilevel Satisfaction)</b>: Let \ltstruct\Gamma, M\gtstruct be a bilevel pair, where \Gamma consists of closed sentences.  Let N be a model in the vocabulary V = vocabulary[\Gamma] \cup vocabulary[M].  N satisfies the pair exactly when N satisfies \Gamma wrt V and the portion of N corresponding to the vocabulary of M is the same as M.
<center>\models_N \ltstruct\Gamma,M\gtstruct if and only if \models_N \Gamma wrt V and Reduct[N,vocabulary[M]] = M</center>

<p>Just as the set of models for an axiomatization \Delta is usually denoted Mod[\Delta], we can use Mod[\ltstruct\Gamma,M\gtstruct] to denote the set of models that satisfy the bilevel pair \ltstruct\Gamma,M\gtstruct.  Entailment in bilevel reasoning can therefore be defined follows.

<p><b>Definition (Bilevel Entailment)</b>: Let P be a bilevel pair and \phi a closed sentence.  P entails \phi exactly when every model that satisfies P satisfies \phi.
<center>P \models\phi if and only if for every M in Mod[P], \models_M\phi</center>

<p>This splitting of axioms and data is convenient, but often it is equivalent to a normal set of sentences in Herbrand logic.

<p><b>Conjecture (Finite Bilevel Equivalent to Herbrand Logic)</b>: Let \ltstruct\Gamma,M\gtstruct be a bilevel pair, where M is finite.  Then there is a  sentence set \Delta in Herbrand logic such that Mod[\Delta] = Mod[\ltstruct\Gamma,M\gtstruct].
<br><b>Proof</b>:  First we construct such a \Delta and then we show that every model that satisfies the pair satisfies it and vice versa.
<p>Start out by including in \Delta every sentence in \Gamma.  Then for each relation r in M, perform the following.  Let {t_1,...,t_n} be the set of ground tuples for which r is satisfied in M.  Note this is a finite set.  Include the sentence, \forallxbar.r(xbar) \Leftrightarrow xbar=t_1 \vee xbar=t_2 \vee ... \vee xbar=t_n.
<p>	To show: \models_N \ltstruct\Gamma,M\gtstruct if and only if \models_N \Delta.  Since \Gamma is included in \Delta, we can remove it from both sides.  Using the definition of bilevel pair satisfaction, we need now show that M = Reduct[N,vocab[M]] if and only if \models_N \forallxbar. r_i(xbar) \Leftrightarrow xbar=t_1 \vee xbar=t_2 \vee ... \vee xbar=t_n for all relations r_i in vocab[M].  
	<p>(\Rightarrow) Suppose M = Reduct[N,vocab[M]] but for the purpose of contradiction there is some r_i such that \not\models_N \forallxbar. r_i(xbar) \Leftrightarrow xbar=t_1 \vee xbar=t_2 \vee ... \vee xbar=t_n.  That is, there is some tbar such that \not\models_N r_i(tbar) \Leftrightarrow tbar=t_1 \vee tbar=t_2 \vee ... \vee tbar=t_n.  That is, there is either some tbar in r_i in the reduct  that is not in {t_1,...,t_n} or there is some tbar not in r_i in the reduct but in {t_1,...,t_n}.  But in both cases, because the reduct of N is M, and {t_1,...,t_n} was constructed to be exactly that set of ground terms in r_i in M, neither of these can be the case.  Contradiction.  
	<p>(\Leftarrow) Suppose N satisfies \forallxbar. r_i(xbar) \Leftrightarrow xbar=t_1 \vee xbar=t_2 \vee ... \vee xbar=t_n for all relations r_i in vocab[M], but for the purpose of contradiction M \ne Reduct[N,vocab[M]].  That is there is some r(ubar) extra in N or missing in N.  Suppose the former, that r(ubar) is in Reduct[N,vocab[M]] but not M, i.e. ubar is not in {t_1,...,t_n}.  Then N could not satisfy \forallxbar. r(xbar) \Leftrightarrow xbar=t_1 \vee xbar=t_2 \vee ... \vee xbar=t_n since ubar is none of the t_i.  Likewise, if r(ubar) is in M but missing from Reduct[N,vocab[M]] then again N cannot satisfy \forallxbar. r(xbar) \Leftrightarrow xbar=t_1 \vee xbar=t_2 \vee ... \vee xbar=t_n since this sentence entails r(ubar).  Contradiction. \qed

<p>Clearly then every finite bilevel pair can be encoded as a finite set of Herbrand logic sentences.  However, as we shall see, deductive databases and to a lesser extent formal verification take advantage of this separation.  They along with CSPs and logic programming can be defined as subsets of a very special class of bilevel pairs--those with exactly one satisfying model.  

<p>In first-order logic, a set of axioms whose models are all elementarily equivalent, i.e. indistinguishable wrt first-order sentences, is said to be axiomatically complete.  This means every sentence in the language or its negation is entailed by the axioms.

<p><b>Definition (Axiomatic Completeness)</b>: Let L be a language and \Delta a set of sentences.  \Delta is axiomatically complete if and only if for every closed sentence s in L, \Delta entails s or \Delta entails \negs or both.

<p>In Herbrand logic, if a set of sentences is axiomatically complete, those sentences are satisfied by exactly one model.  (The fact that axiomatic completeness in Herbrand logic has different model-theoretic properties than first-order logic stems from the fact that Herbrand logic fixes the equality relation, whereas first-order logic does not.)  Likewise, we will say that a bilevel pair is (axiomatically) complete if and only if it has a single model. 

<p><b>Definition (Complete Bilevel Pair)</b>: A bilevel pair P is complete if and only if Mod[P] is either a singleton set or the empty set.

<p><b>Definition (Complete Bilevel Axioms)</b>: A set of bilevel axioms \Gamma is complete wrt vocabulary V if and only if for every model M in V such that P=\ltstruct\Gamma,M\gtsruct is satisfiable, P is a complete bilevel pair.

<p>It is sometimes natural to think of \Gamma as simply extending the theory defined by M, a small wrinkle on the notion of a conservative extension to a logical theory.  

<p><b>Definition (Conservative Pair)</b>: A pair P=\ltstruct\Gamma,M\gtstruct is conservative exactly when every sentence in Cn[P] that is in vocabulary[M] is a consequence of M itself, i.e. when it is in Th[M].

<p><b>Definition (Conservative Bilevel Axioms)</b>: A set of axioms \Gamma is conservative wrt vocabulary V if and only if for every model M in V, \ltstruct\Gamma,M\gtstruct is a conservative pair.

<p>Deductive databases, constraint satisfaction, logic programming, and formal verification can all be defined as complete bilevel pairs.

<br><br><p><center>
[<a href="#bilevel">Bilevel Reasoning</a> 
| <a href="#db">Deductive Databases</a> 
| <a href="#csp">Constraint Satisfaction</a>
| <a href="#lp">Logic Programming</a>
| <a href="#fv">Formal Verification</a> ]</center><br>



<a name="db"><h1>Deductive Databases</h1></a>

<p>A database is complete bilevel pair where the model that satisfies the pair is finite.  Two standard options exist for defining the set of object constants in the vocabulary: (1) it consists of those object constants that appear in P or (2) it is the set of all object constants, i.e. it includes infinitely many object constants.  We will assume the former: that the set of object constants is just those that appear in P.

<p>Let \ltstruct\Gamma,M\gtstruct be a database.  Using the conventional database terminology, the set of relations defined in M is the set of extensional database predicates (EDBs), i.e. the base tables, and the remaining relations comprise the set of intensional database predicates (IDBs), i.e. the views.  When there are no IDBs, a database is just a Herbrand model, and there is always at least one EDB in every database.

<!-- <p>For example, consider a simple database (Herbrand model).
<indent>{p(a), p(b), q(a)}</indent>
For the vocabulary {p, a, b}, this model satisfies the sentence \forallx.p(x).  If later the sentence q(c) were added, the database would become
<indent>{p(a), p(b), q(a), q(c)}</indent>
Clearly, the universe for the model must include a,b,c which means that it no longer satisfies \forall x.p(x).  This nonmonotonic result can occur when the universe is defined using option (1) above but not when using option (2).   In fact, \forallx.p(x) will never be satisfied using option (2) because a database is defined as a finite Herbrand model.  Satisfying \forallx.p(x) would require a model where p is true of infinitely many objects, which cannot happen in a finite model.  -->

<!-- <p>By keeping the vocabulary and universe unknown, the original database does not satisfy \forall x.p(x) for the simple reason that the database <i>never</i> satisfies \forall x.p(x).  Since such a query is always false, database query languages do not allow one to ask universal queries.  Thus, answering a database query amounts to checking whether some sentence \exists^*.\phi(x_1,...,x_n) is satisfied by the model, or more precisely, it amounts to finding all the x_1,...,x_n such that the model satisfies \phi(x_1,...,x_n). -->

<p>A database query always takes the following form: find all the x_1,...,x_n such that the database satisfies the query \phi(x_1,...,x_n).  Various languages exist for expressing that query; here we discuss Datalog with negation, which is often used to define IDBs.  Because a database is a complete pair, Datalog has been designed so that the negative consequences need not be written down (just like in a Herbrand model) but at the same time every set of Datalog rules can always be assigned a unique model.  This turns out to be a little tricky with negation.  As we shall see, this allows us to define a database as a bilevel pair in a fairly straightforward way: the model is the set of EDB predicates and the axiom set defines the IDB predicates with Datalog.  The rest of this section defines Datalog with negation and discusses how to ensure a set of Datalog rules can be assigned a unique model.

<p><b>Definition (Datalog Rule)</b>: A Datalog rule is an implication (where traditionally :- is used instead of \Leftarrow and , is used in place of \wedge).
<indent>h \Leftarrow b_1 \wedge  b_2 \wedge ... \wedge b_n
- The head, h, is an atomic sentence.
- Each element in the body, b_i, is a literal.
- There are no function constants.
- Safety: if a variable appears in the head or in a negative literal, it must appear in a positive literal in the body. 
</indent>

<p>(Usually, Datalog allows various arithmetic operations in the body of rules, e.g. addition and multiplication, but we ignore those operations here.  Also, the above definition is usually called datalog^{\neg}.)

<p>Datalog is usually viewed as a language for defining a larger database from a smaller one.  It defines the contents of new relations based on the contents of the original relations, in the end producing a single model/database.  Because Herbrand semantics allows multiple models to satisfy a particular set of sentences, as stated it is inappropriate for defining the semantics of Datalog rules.  Three variations on Herbrand semantics are often used as the semantics for Datalog: minimal Herbrand semantics with stratified negation, stable model semantics, and well-founded semantics.  We leave discussion of stable model semantics to the section on Prolog; well-founded semantics relies on 3-valued logic, which we do not address.

<p>If a set of Datalog rules has no negation, i.e. when every literal in the body of every rule is an atom, it is Horn.  It is well-known that Horn rules have a well-defined minimal model (as measured by the number of ground atoms in the Herbrand model), and the semantics for such a set of rules is defined to be that model.  When the rules do include negation, the minimal model is not necessarily well-defined.  For example, the sentence
<indent>p(a) \Leftarrow not q(a)</indent>
is logically equivalent to
<indent>p(a) \vee q(a)</indent>
which has two minimal models: {p(a)} and {q(a)}.

<p>While negation does present some problems for the notion of a minimal Herbrand semantics, certain forms of negation do have well-defined minimal models.  Stratification is one such form.  It is defined in terms of a dependency graph.

<p><b>Definition (Dependency graph)</b>: Let \Delta be a set of Datalog rules.  The nodes of the dependency graph for \Delta are the relation constants in the vocabulary.  There is an edge from r_2 to r_1 whenever there is a rule with r_1 in the head and r_2 in the body.  That edge is labeled with \neg whenever r_2 is in a negative literal.

<p><b>Definition (Datalog Stratification)</b>: A set of Datalog rules are stratified when its dependency graph contains no cycle through a negative edge.  Stratum 0 is the set of all nodes without incoming edges.  Stratum 1 is the set of all nodes adjacent to a node in stratum 0; stratum i+1 is the set of all nodes adjacent to a node in stratum i that are not in stratum i.

<p>Clearly, if there is no negation, the graph has no \neg edges, which means it has a single stratum and is stratified.  When a set of Datalog rules is stratified, we can always choose a single Herbrand model as its semantics.  Stratum 0 contains no negation; thus it has a minimal model.  The minimal model for stratum i+1 is constructed by extending the minimal model for stratum i by evaluating the body of all rules in stratum i+1 in the minimal model of stratum i.  

<p><b>Definition (Stratified Datalog Semantics)</b>: Let S be a set of stratified Datalog rules.  Let M_0 be the minimal models that satisfies all the rules in stratum 0.  To compute M_i, where i &gt; 0, initialize M_i to M_{i-1}.  Perform the following operations, adding the result to M_i until no changes occur.
<ul><li>Let h \Leftarrow b_1 \wedge ... \wedge b_n be a rule in stratum i.
<li>For each substitution \sigma such that \models_{M_i} (b_1\wedge ... \wedge b_n)\sigma, output h\sigma.  
</ul>
Let k be the largest stratum for any rule in S (and we're guaranteed there is such a finite k).  The Stratified Datalog Semantics of S is M_k. \qed

<p>For example, consider the following stratified rules.  (Traditionall not is used in place of \neg.)
<indent>p(a) \Leftarrow \negq(a)
q(b) \Leftarrow not t(b)
t(c)
</indent>
The minimal model for these sentences is computed as follows.  Stratum 0 is just {t}; stratum 1 is {q}, and stratum 2 is {p}.  For stratum 0, the minimal model is just <indent>{t(c)}.</indent>  The only rule in stratum 1 is the one with q in its head: q(b) \Leftarrow not t(b).  The body not t(b) is true in the model {t(c)}. Thus, the minimal model for stratum 1 is 
<indent>{t(c), q(b)}.</indent>
For stratum 2, the rule body of p(a) \Leftarrow  \negq(a) is true in {t(c), q(b)}, making the minimal model for this set of Datalog rules <indent>{t(c), q(b), p(a)} \qed</indent>

<p>Variables in negative literals can be problematic.  Consider the rule set
<indent>p(x) \Leftarrow \negq(x)
q(a)</indent>  The minimal model for stratum 0 is {q(a)}.  The minimal model for stratum 1 requires computing all the x such that not q(x) is true.  If the vocabulary were known, an implementation could, when faced with such a rule, enumerate all the object constants in that vocabulary, using NAF on each grounding of the literal.  But because the vocabulary is never known in a database, no enumeration can occur.  However, for the case where negative literals can always be evaluated over the known vocabulary, the minimal model can be computed.

<p>The definition for a Datalog rule includes a statement that says for an implication to be a Datalog rule, it must obey the following constraint: if a variable appears in the head of the rule or a variable appears in a negative literal, that variable must also appear in a positive literal in the body.  Now that the semantics have been defined, the reason for this constraint can be explained.  
<p>Suppose we were to write a rule with a variable in the head that does not occur in the body or a rule with a variable in a negative literal that does not occur in the body.

<indent>p(x,y) \Leftarrow q(x)<br>
s(a) \Leftarrow \neg r(y)
</indent>

In the first case, suppose q(a) is true.  Then p(a,x) is also true.  If, as is sometimes the case, the set of object constants is very large or infinite (see the note at the start of the section on defining the object constants in the vocabulary of a database), the model may be very large or infinite.  In the latter case, the result no longer falls under the definition of a database, as every database must be assigned a single, finite model.  The constraint above removes this possibility by forcing every variable in the head of the rule to occur in a positive literal in the body.  This condition is sufficient to ensure that a finite set of rules (without function constants) always has a finite model as its semantics.

<p>In the second rule above, it is unclear how to interpret what the rule is supposed tomean.  Does it mean that if there is some y for which r is false that s(a) is true?  Or does it mean that if r(t) for every ground term t is false that s(a) is true? the constraint on Datalog rules removes this ambiguity by requiring every variable in a negative literal to also occur in a positive literal in the body; by first evaluating the poositive literal, every negative literal can be ground before evaluating it using negation as failure.

<p>Now that the syntax and semantics of Datalog have been covered, we can return to the earlier promise of defining a database in terms of a bilevel pair.

<p><b>Observation (Database as a Bilevel pair)</b>: A database is a bilevel pair \ltstruct\Gamma,M\gtstruct, where \Gamma is a finite set of Datalog rules that has no EDB predicate in the head of any rule.


<p>We now turn to some decidability results.  Because Datalog does not allow function constants, the number of Herbrand models for any finite vocabulary is finite.  Regardless which semantics are used, as long as the semantics assigns some subset of all Herbrand models over a finite vocabulary to a set of sentences and checking satisfaction in one of those models is decidable, entailment is decidable.

<p><b>Theorem (Datalog is Decidable)</b>: Let \Delta be a finite set of Datalog rules.  Let S be a semantics for Datalog that chooses some subset of the Herbrand models over the vocabulary induced by \Delta, where checking whether a model satisfies \Delta is decidable.  Let \phi be the query. 
<center>\Delta \models \phi under the semantics S is decidable.</center>
<br><b>Proof</b>:  Since \Delta itself is finite, the vocabulary and therefore the number and size of all Herbrand models over that vocabulary is finite.  Because satisfaction in S is decidable, to check entailment, enumerate each model for the vocabulary and when it satisfies \Delta check whether it satisfies \phi.  If every model that satisfies \Delta satisfies \phi, \Delta \models \phi.  Otherwise \Delta \not\models \phi. \qed

<p>Unlike theorem proving, answering a query in a database usually means finding all the tuples for which the query is satisfied.  We call this materializing the query.

<p><b>Definition (Materialization)</b>: Let \Delta be a set of sentences and \phi(x_1,...,x_n) be a query with free variables x_1,...,x_n.  The materialization of the query for \Delta is the set of all &lt;t_1,...,t_n&gt; such that \Delta \models \phi(t_1,...,t_n), where each t_i is ground.


<p><b>Corollary (Materializing Datalog is Decidable)</b>: Same conditions as the last theorem.  \phi has the free variables x_1,...,x_n.  Materializing \phi for \Delta is decidable.
<br><b>Proof</b>: Let \sigma be some substitution x_1/c_1,...,x_n/c_n, where each c_i is an object constant in the vocabulary of \Delta.  By the above theorem \Delta \models \phi\sigma is decidable.  If \Delta \models \phi\sigma, add the tuple &lt;c_1,...,c_n&gt; into the materialization.  Since \phi is finite, the number of variables is finite; since \Delta is finite, the number of object constants is finite.  Thus, the number of distinct \sigmas is finite; check entailment for each one and return the resulting set of tuples. \qed


<h2>Completeness and NAF implementation</h2>

<p>Minimal Herbrand semantics, whatever the form, ensures that at most one model satisfies a given set of Datalog rules.  Assuming the rules are consistent, the consequences of those rules is an axiomatically complete theory.

<p>When a theory in a complete logic, i.e. a logic with a complete proof procedure, is axiomatically complete and has a recursively enumerable axiomatization, the theory is decidable: for any query \phi, interleave proof attempts for \phi and \neg \phi.  One of them is entailed, and because the logic is complete, the proof will be found.  In such a theory, negation as failure (NAF) is monotonic: failing to prove \phi ensures that \neg \phi is entailed.  

<p><b>Definition (Negation as Failure)</b>: Negation as failure is the following inference rule:
<center><table border="0">
<tr><td style="border-bottom: 1px solid black">\Delta \not\models \phi</td></tr><tr><td>\Delta \models \neg\phi</td></tr></table></center>

<p>NAF is monotonic whenever \Delta entails either the query in question or its negation, i.e. \Delta is complete for the language that includes either the query or its negation.  

<p><b>Theorem (Monotonic NAF)</b>: NAF is monotonic for a particular query \phi if and only if the theory is complete wrt the language {\phi}. 
<br><b>Proof</b>: 
<indent>\Delta \models \phi \vee \Delta \models \neg\phi (\Delta is complete)
		\Leftrightarrow \neg (\Delta \models \phi) \Rightarrow \Delta \models \neg\phi (Logical equivalence of p \vee q and \neg p \Rightarrow q)
 		\Leftrightarrow \Delta \not\models \phi \Rightarrow \Delta \models \neg\phi (Every query is either entailed or not entailed)\qed</indent>
		

<p>Because the Stratified Datalog semantics assigns a single model to a set of rules, it ensures every theory is axiomatically complete.  The above theorem ensures NAF is monotonic for every query.  One benefit to these semantics is that there need be no rules with negative literals in the head, which is reflected in the definition of Datalog rules.  

<p>Since the negative portion of the theory is never explicitly written, a proof system for Datalog must rely on NAF.  The definition of Stratified Semantics can be implemented directly, causing the proof system to construct the minimal model by constructing one stratum after another in a bottom-up fashion.  Some implementations, on the other hand, start with the query and use the rules backwards.  They evaluate negative literals in rule bodies with NAF: attempt to prove the positive version of the literal, and if that fails, conclude that the negative version must be true.  If not done carefully, the proof procedure can fail to find a proof even when one exists.

<p>For example, consider the following rule-set.
<indent>p(x,y) \Leftarrow p(x,z) \wedge p(z,y)
q(a) \Leftarrow not p(a,a)
q(a)</indent>

These rules are stratified; they have the following model: {q(a)}.  The first rule says that p is transitive.  The second rule says that q(a) is true if p(a,a) cannot be proven.  The third rule says that q(a) is true.  If the query is q(a), here is what the proof trace might look like.  
<indent>q(a) is true if p(a,a) cannot be proven
p(a,a) can be proven if p(a,z) and p(z,a) can be proven
p(a,z) can be proven if p(a,w) and p(w,z) can be proven
...</indent>
Simple iterative deepening does not help here since NAF launches a brand new proof attempt for p(a,a), and iterative deepening on p(a,a) will run forever.  If iterative deepening is to be used with NAF, depth limits must be shared among proof attempts.

<p>This example illustrates another problem with the top-down approach: while answering a Datalog query has been shown decidable, the top-down approach does not always terminate it.  The query p(a,a) may run forever.
 
<br><br><p><center>
[<a href="#bilevel">Bilevel Reasoning</a> 
| <a href="#db">Deductive Databases</a> 
| <a href="#csp">Constraint Satisfaction</a>
| <a href="#lp">Logic Programming</a>
| <a href="#fv">Formal Verification</a> ]</center><br>


<a name="csp"><h1>Constraint Satisfaction Problems</h1></a>
<p>Finite constraint satisfaction problems turn out to be a subclass of database queries.  Infinite constraint satisfaction problems would also fall into a subclass of database queries if databases were allowed to be infinitely large.  However, instead of finding all solutions to the query as is done in databases, a constraint satisfaction problem is solved once any one solution is found.

<p><b>Definition (Constraint Satisfaction Problem)</b>: A constraint satisfaction problem is a three-tuple \ltstructV,D_V,C_V\gtstruct:
<indent>V: set of variables
D_V: for each variable, a set of values, i.e. its domain
C_V: a set of constraints that say which combinations of variables can be assigned which combinations of values
</indent>
A solution to a CSP is an assignment of values to variables so that every variable is assigned a value from its domain and every constraint is satisfied. \qed

<p>Mathematically, the constraints in a CSP can be defined as tables of the allowed values.  For example if variables v_1 and v_2 have the same domain {a,b,c} but some constraint says those variables can only be assigned different values, that constraint is mathematically equivalent to the following table.

<center><table border="1">
<tr><th>v_1</th><th>v_2</th></tr>
<tr><td>a</td><td>b</td></tr>
<tr><td>a</td><td>c</td></tr>
<tr><td>b</td><td>a</td></tr>
<tr><td>b</td><td>c</td></tr>
<tr><td>c</td><td>a</td></tr>
<tr><td>c</td><td>b</td></tr>
</table></center>

<p>A set of constraints is then a set of tables, where each column is labeled with a variable name.  In the context of databases, these  tables labeled C_i is correspond to the EDBs.  In logic, we encode the table for constraint C_i as the set of all ground atoms of the form C_i(t_1,...,t_n), where n is the number of columns and t_1,...,t_n is some tuple in the table.   The CSP is solved by a variable assignment that satisfies all the constraints.  The set of all such variable assignments is defined by the following conjunction.  For each table C_i with columns labeled v_1,...,v_m, include the conjunct C_i(v_1,...,v_m).  This is a special kind of database query--a conjunctive query or equivalently a select-project-join query.  Or equivalently, the query is just the natural join on all the tables.    

<p>For example, suppose there were two of the tables as shown above: C_1 and C_2, the first labeled the same as above, v_1 on the left and v_2 on the right, and the second labeled differently, v_2 on the left and v_3 on the right.  The constraint satisfaction problem would be asking for an assignment v_1/t_1, v_2/t_2, and v_3/t_3 so that &lt;t_1,t_2&gt; is a tuple in the C_1 table and &lt;t_2,t_3&gt; is a tuple in the C_2 table.  The corresponding conjunctive query would be C_1(v_1,v_2) \wedge C_2(v_2,v_3).  All solutions to that query over those tables is the following, which is equivalent to the natural join of C_1 and C_2.

<center><table border="1">
<tr><th>v_1</th><th>v_2</th><th>v_3</th></tr>
<tr><td>a</td><td>b</td><td>a</td></tr>
<tr><td>a</td><td>b</td><td>c</td></tr>
<tr><td>a</td><td>c</td><td>a</td></tr>
<tr><td>a</td><td>c</td><td>b</td></tr>
<tr><td>b</td><td>a</td><td>b</td></tr>
<tr><td>b</td><td>a</td><td>c</td></tr>
<tr><td>b</td><td>c</td><td>a</td></tr>
<tr><td>b</td><td>c</td><td>b</td></tr>
<tr><td>c</td><td>a</td><td>b</td></tr>
<tr><td>c</td><td>a</td><td>c</td></tr>
<tr><td>c</td><td>b</td><td>a</td></tr>
<tr><td>c</td><td>b</td><td>c</td></tr>
</table></center>

<p>The constraints in a CSP are often stated more compactly, in Datalog.  At first, this equivalence of CSPs with a subset of databases is disconcerting since solving a CSP is well-known to be NP-Complete and answering queries in databases is often considered to be polynomial.  To rectify this seeming contradiction, it is sufficient to note that solving a CSP is NP-hard in terms of the number of variables.  Solving a database query is polynomial in terms of the data, i.e. in terms of the size of the model; it is exponential in the number of variables in the query.  Thus, database queries are in practice usually polynomial because the size of the data vastly exceeds the size of the query--the major cost in answering a database query is in manipulating the data.    Not independently, the number of answers to a query is often much larger than the number of variables in the problem, which gives further support for ignoring the number of variables, as is often done in the database community.

<p><b>Observation (CSP as a Bilevel pair)</b>: In the context of bilevel reasoning, a CSP is a bilevel pair \ltstruct\Gamma,M\gtstruct, where \Gamma is empty, and the only query of interest is the natural join over all the relations in M (if we gave names to each argument of each relation).


<br><br><p><center>
[<a href="#bilevel">Bilevel Reasoning</a> 
| <a href="#db">Deductive Databases</a> 
| <a href="#csp">Constraint Satisfaction</a>
| <a href="#lp">Logic Programming</a>
| <a href="#fv">Formal Verification</a> ]</center><br>



<a name="lp"><h1>Logic Programming</h1></a>

<p>This section is entitled Logic Programming, though with some apprehension.  Truly this section is about Prolog and variants of it--a family of languages that were developed to program computers where all the logic is in rule form, and negation as failure is prevalent.  Logic programming on the other hand is the far more general paradigm of programming a computer using formal logic itself, regardless the syntax or semantics.  It is noteworthy that Prolog and its variants have become so popular that they have become synonymous to some extent with the term logic programming.

<!-- (I personally find naming concepts very tiresome.  Logic programming is a good name; using it to refer to a particular implementation only diminishes its value.  And, because the term Logic Programming is often used in the literature, our use of the term Prolog is nonstandard and therefore worth noting.) -->

<p>Prolog can be seen as a generalization of Datalog, and in the context of Bilevel reasoning, it is a complete bilevel pair \ltstruct\Gamma,M\gtstruct, where M can be empty.    Function constants come into the picture, certain restrictions are removed, and a more general rule form is often allowed.  

<p><b>Definition (Prolog Rule)</b>: A Prolog rule is an implication (where traditionally :- is used instead of \Leftarrow and , is used in place of \wedge).
<indent>h_1 \vee ... \vee h_m \Leftarrow b_1 \wedge b_2 \wedge ... \wedge b_k, not b_{k+1} \wedge ... \wedge not b_n
- each h_i is a classical literal, e.g. p(a) or \negp(a).
- each b_i is a classical literal.
- each not b_j is a NAF literal, e.g. not p(a) or not \neg p(a)  \qed
</indent>

<p>When compared to the definition of a Datalog Rule, (1) disjunction is allowed in the head, (2) classical negation is allowed everywhere , (3) variables are unrestricted, and (4) function constants are allowed.  What we shall call <i>vanilla Prolog</i> does not allow (1) or (2).  It is this version of Prolog we assume from this point on, making the definition as follows.

<p><b>Definition (Vanilla Prolog Rule)</b>: A vanilla Prolog rule is an implication.
<indent>h \Leftarrow b_1 \wedge b_2 \wedge ... \wedge b_n
- h is an atom.
- each b_i is a NAF literal, e.g. p(a) or not p(a). \qed</indent>

<p>Just as with Datalog, a set of Prolog sentences without negation can be assigned a single, minimal model; that model happens to be the intersection of all the Herbrand models of those sentences.  Negation presents difficulties in Prolog just like it did with Datalog.  

<p>The Stratified Datalog semantics works equally well with function constants, but researchers have found stratification sometimes too restrictive; two definitions for the semantics of Prolog rules with negation stand out.  [Gelfond and Lifschitz 1988] introduced Stable Model Semantics, and [Gelder, Ross, and Schlipf 1991] introduced Well-founded semantics.  Stable model semantics are closer to Herbrand semantics than minimal Herbrand semantics: a Prolog theory under stable model semantics is not necessarily axiomatically complete, i.e. instead of assigning a single model to a set of sentences, it assigns multiple models.  Well-founded semantics relies on a 3-valued logic, which in some sense compresses multiple models into a single one.  Here we discuss only stable model semantics.  These semantics do not naturally fit into the complete bilevel pair formalism, the stratified semantics do.   

<p>Propositional stable model semantics relies on the notion of a stable model, which in turn relies on the Gelfond-Lifschitz transformation.

<p><b>Definition (Gelfond-Lifschitz Transformation)</b>: Let \Delta be a set of ground vanilla Prolog rules and M a Herbrand model in the vocabulary of \Delta.  The Gelfond-Lifschitz transformation of \Delta with respect to M is defined as follows.
<ol>
<li>Delete any rule in \Delta with a literal not b_i in the body where b_i \in M.
<li>Delete all negative literals from rules in \Delta.
</ol>
Denote this by GL[\Delta,M]. \qed

<p>The result of this transformation with respect to a model M is a set of rules without negation.  If M is minimal, it is a stable model.

<p><b>Definition (Stable Model)</b>: Let \Delta be a set of ground vanilla Prolog rules and M a Herbrand model in the vocabulary of \Delta. M is a stable model of \Delta if and only if M is the minimal satisfying model of GL[\Delta,M].

<p>There will always be exactly one minimal model of GL[\Delta,M] since it is Horn.

<p><b>Definition (Propositional Stable Model Semantics)</b>: Let \Delta be a set of ground vanilla Prolog rules.  \Delta \models \phi if and only if every stable model of P satisfies \phi.

<p><b>Definition (Stable Model Semantics)</b>: Let \Delta be a set of vanilla Prolog rules.  Let \Delta' be all ground instantiations of the rules in \Delta.  \Delta \models \phi if and only if \Delta' \models \phi.

<p>Regardless which semantics are chosen, a query in Prolog is a single atomic sentence.  If the query \phi = p(t_1,...,t_n) has variables, four options arise for answering the query: (1) return T if \exists*\phi is entailed by the vanilla Prolog rules, (2) return some variable assignment \sigma such that the rules entail \phi.\sigma, (3) return a function that iteratively returns such variable assignments, or (4) return all such variable assignments.  Part of the reason (3) and (4) are not considered in Datalog is that every Datalog query has finitely many answers, whereas in Prolog there may be infinitely many answers.  

<p>Recall that answering entailment queries in Datalog is decidable, as is finding all answers to Datalog queries.  The addition of functions ensures that undecidable problems can be embedded in Prolog, even without employing negation (see the comments about encoding Diophatine equations  on <a href="modeltheory-prooftheory.html">Proof and Model Theory</a>).  That is, entailment queries for recursive Horn rules with functions is undecidable.  Removing either functions or recursion regains decidability.

<p><b>Theorem</b>: Entailment for Horn Prolog is undecidable.
<p><b>Theorem</b>: Entailment for non-recursive Horn Prolog is decidable.
<p><b>Theorem</b>: Entailment for function-free Horn Prolog is decidable.
 
<p>For more information on the semantics of Prolog and its variants, Lifschitz's paper entitled <a href="http://www.cs.utexas.edu/users/vl/mypapers/flp.ps">Foundations of Logic Programming</a> surveys various semantic definitions and their computational consequences.  It focuses on rules that include classical negation and on stable model semantics, closely connected to answer set programming.



<br><br><p><center>
[<a href="#bilevel">Bilevel Reasoning</a> 
| <a href="#db">Deductive Databases</a> 
| <a href="#csp">Constraint Satisfaction</a>
| <a href="#lp">Logic Programming</a>
| <a href="#fv">Formal Verification</a> ]</center><br>

<a name="fv"><h1>Formal Verification</h1></a>
<p>Formal verification at a very high level involves defining how a system works and asking whether that system obeys some property.  For example, given a computer program written in C, does it ever access an element of an array before allocating the memory for that array?  Here we consider a very simple class of systems: finite state machines that run forever.  While this class is simple, it should be noted that it is complex enough to model the workings of any modern-day computer.  

<p>First we show how to use a bilevel pair to define a system, and then we show how to phrase queries about that system.

<p><b>Definition (Finite State Machine)</b>: A finite state machine (FSM) is a tuple \ltstructS, \Sigma, S_0, S_f, \delta\gtstruct.  
<indent>S: set of states
\Sigma: input vocabulary
S_0: the initial state -- S_0 \in S
S_f: the final states -- S_f \in S
\delta: the transition function: Sx\Sigma \rightarrow S.
<\indent>

<p>It turns out to be convenient to use Vanilla Prolog with stratified semantics, i.e. Datalog with function constants, for encoding the FSM.  Now we explain how to describe a finite state machine as a bilevel pair \ltstruct\Gamma,M\gtstruct.

<p>Representing a FSM as a shown above may require a large amount of space; simply because the set of states may be very large.  Often, though, the states in a system need not be described as monolithyic states but rather can be described using a set of propositions, where a state is defined as the set of propositions true in the state. Those propositions will be represented by ground terms.

<p>The model M defines the propositions true in the initial state, S0.  If for example the propositions p, q, and r are true in the intial state, and only those are true in the initial state, then the model is.
<indent>init(p)
	init(q)
	init(r)
</indent>

<p>The dynamics of most systems are the same regardless what the initial state is.  Those dynamics (\delta) tell us for a given state and a given input what the next state will be.  To represent that proposition p is true in state s, we write
<indent>true(p,s)
</indent>

<p>To represent names for states, we will borrow from situation calculus.  Each state may have many names; each name encodes the history of actions required to reach that state from the initial state.  This reflects the fact that even though there are a finite set of states in a FSM, any one state may be reached arbitrarily many times by performing longer and longer sequences of actions from the initial state.

<p>Thus, actions too take the form of propositions, and when encoded in logic the form of ground terms.  If the proposition p is true in the state resulting from executing actions a,b,c from the initial state, we can express this as follows.
<indent>true(p, do(c, do(b, do(a, s0))))
</indent>
Notice that the last action executed is the first one in the name of the state when read from left to right.

<p>To tie the initial state to the state name s0, we need a single rule.
<indent>true(x,s0) <= init(x)</indent>

<p>Using simple implications, we can encode how certain actions affect the state of the world.  Blocks world is a simple example.  If blocks x and y are clear in state s (all of which are variables) then by executing the action stack(x,y) in s, the resulting state includes the proposition on(x,y).  

<indent>true(on(x,y), do(stack(x,y),s)) \Leftarrow legal(stack(x,y), s)
legal(stack(x,y), s) \Leftarrow true(clear(x),s) ^ true(clear(y),s)
</indent>

<p>Frame axioms, sentences that say what things do not change as a result of an action, must also be encoded.  For example, if block x is on block y then performing the stack action does not change that fact.  (Conditioning the rule on x and y being clear ensures the action is not executed unless it is legal to do so.

<indent>true(on(x,y), do(stack(z,w), s)) \Leftarrow true(on(x,y), s) ^ legal(stack(x,y), s)
</indent>

<p>Datalog is useful here since it ensures that every proposition that cannot be proven true in a state is in fact false in that state, without having to write down all the rules that say so.

<p>The set of all rules that define the transition function \delta also define the input vocabulary \Sigma.  \Sigma is the set of all ground action names.  The remaining element of a FSM that must still be defined is the set of final states, Sf.  To do that, we use a distinguished unary relation terminal.  Whenever terminal holds in a state, the state is a terminal state, i.e. a member of Sf.  For example, to say the system is terminal when block a is on b and block b is on c, we could write the following.
<indent>terminal(s) <= true(on(a,b),s) ^ true(on(b,c),s)
</indent>

<p>To be faithful to the FSM notion of a terminal state, the rules for terminal should never distinguish states based on the state names, i.e. on the action taken to reach the current state.  In other words, terminal(s) should always be at the head, and no action should ever be mentioned in the body.

<p>The examples define a transition function as one would expect: given a state and an action, the rules say what the subsequent state looks like.  But one could write more interesting rules where the state an arbitrary number of steps in the future determines what must have happened in the past.

<indent>true(p, s) <= true(p, do(a, do(b, s)))
</indent>

<p>Such rules can easily lead to inconsistency, and are never necessary for defining a finite state machine (though sometimes such rules are convenient).  In the case that it is desirable to force a system description where the transition function is expressed only as the effects of an action on a current state, i.e. a Markov version of what is shown above, there is a language called <a href="http://logic.stanford.edu/reports/LG-2006-01.pdf">GDL</a>.  It ensures decidability and finiteness, and can be easily translated into the form seen here.

<h3>Formal Verification Queries</h3>
The discussion above illustrates how to construct a bilevel pair that defines the system we might like to verify.  Some kinds of formal verification can be seen as just answering entailment questions about that bilevel pair.

<p>For example, let's say we want to ask whether in every state reachable from the initial state the action a is legal.

<p>First, we need to define which states are reachable.  Again, we use Datalog to ensure we know which states are reachable and which states are not reachable.
<indent>reachable(s0)
reachable(do(x,s)) <= legal(x,s) ^ reachable(s)
</indent>
Then, asking whether action a is legal in every reachable state is easy. 
<indent> As. reachable(s) => legal(a,s)
</indent>

<p>Is there a legal move in each reachable state?
<indent>As. reachable(s) => Ea. legal(a,s)
</indent>

<p>Not every formal verification query can be phrased as a finite axiom about a bilevel pair. without extending the set of ground terms (and therefore the set of models.  For example, does some property p hold over every subset of reachable states?  Because the set of states can be arbitrarily large (depending on the model M), any relation of fixed arity will not be able to define any subset with more elements than the arity.  Even if we were to extend the language with function constants to allow lists, the set of reachable state names could be countably large, which ensures the set of all subsets is uncountable.  Clearly we cannot represent uncountably large sets in Herbrand logic since every model has only countably many elements.  (Of course, if we were only interested in all the finite subsets of the reachable states, that set is still countable, and we could express it in Herbrand logic.)


<br><br><p><center>
[<a href="#bilevel">Bilevel Reasoning</a> 
| <a href="#db">Deductive Databases</a> 
| <a href="#csp">Constraint Satisfaction</a>
| <a href="#lp">Logic Programming</a>
| <a href="#fv">Formal Verification</a> ]</center><br>







